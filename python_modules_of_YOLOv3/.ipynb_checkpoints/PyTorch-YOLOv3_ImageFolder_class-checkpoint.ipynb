{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch-YOLOv3 ImageFolder类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 2, 5, 8, 11]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sorted是一个排序\n",
    "g = [1, 5, 2, 8, 11, 2]                                                 \n",
    "sorted(g)                                                                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['w', 't', 's', 's', 'o', 'g', 'g', 'f', 'd', 'a']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted('gaftowsgsd')                                                    \n",
    "sorted('gaftowsgsd', reverse=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./parser/parser1.py', './parser/parser2.py', './parser/rcnn_parser.py']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# glob是python自己带的一个文件操作相关模块，用它可以查找符合自己目的的文件\n",
    "import glob\n",
    "\n",
    "glob.glob(r'./parser/*.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['parser/parser1.py', 'parser/parser2.py', 'parser/rcnn_parser.py']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob(r'%s/*.py' % 'parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/lsc/a409/users/lisuicheng/Machine_learning/PyTorch-YOLOv3/data/samples/20190122car.jpg',\n",
       " '/home/lsc/a409/users/lisuicheng/Machine_learning/PyTorch-YOLOv3/data/samples/20190122people.jpg',\n",
       " '/home/lsc/a409/users/lisuicheng/Machine_learning/PyTorch-YOLOv3/data/samples/dog.jpg',\n",
       " '/home/lsc/a409/users/lisuicheng/Machine_learning/PyTorch-YOLOv3/data/samples/eagle.jpg',\n",
       " '/home/lsc/a409/users/lisuicheng/Machine_learning/PyTorch-YOLOv3/data/samples/giraffe.jpg',\n",
       " '/home/lsc/a409/users/lisuicheng/Machine_learning/PyTorch-YOLOv3/data/samples/herd_of_horses.jpg',\n",
       " '/home/lsc/a409/users/lisuicheng/Machine_learning/PyTorch-YOLOv3/data/samples/img1.jpg',\n",
       " '/home/lsc/a409/users/lisuicheng/Machine_learning/PyTorch-YOLOv3/data/samples/img2.jpg',\n",
       " '/home/lsc/a409/users/lisuicheng/Machine_learning/PyTorch-YOLOv3/data/samples/img3.jpg',\n",
       " '/home/lsc/a409/users/lisuicheng/Machine_learning/PyTorch-YOLOv3/data/samples/img4.jpg',\n",
       " '/home/lsc/a409/users/lisuicheng/Machine_learning/PyTorch-YOLOv3/data/samples/messi.jpg',\n",
       " '/home/lsc/a409/users/lisuicheng/Machine_learning/PyTorch-YOLOv3/data/samples/person.jpg']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "imgs = sorted(glob.glob(r'/home/lsc/a409/users/lisuicheng/Machine_learning/PyTorch-YOLOv3/data/samples/*'))\n",
    "                    \n",
    "imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[196, 198, 195],\n",
       "        [195, 197, 194],\n",
       "        [195, 197, 194],\n",
       "        ...,\n",
       "        [158, 162, 161],\n",
       "        [157, 162, 158],\n",
       "        [157, 162, 158]],\n",
       "\n",
       "       [[194, 196, 193],\n",
       "        [194, 196, 193],\n",
       "        [193, 195, 192],\n",
       "        ...,\n",
       "        [157, 161, 160],\n",
       "        [157, 161, 160],\n",
       "        [157, 162, 158]],\n",
       "\n",
       "       [[195, 197, 196],\n",
       "        [196, 198, 197],\n",
       "        [196, 198, 197],\n",
       "        ...,\n",
       "        [157, 161, 160],\n",
       "        [157, 161, 160],\n",
       "        [157, 162, 158]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 46,  58,  54],\n",
       "        [ 45,  57,  53],\n",
       "        [ 47,  59,  55],\n",
       "        ...,\n",
       "        [ 58,  59,  51],\n",
       "        [ 60,  60,  50],\n",
       "        [ 62,  59,  50]],\n",
       "\n",
       "       [[ 47,  59,  55],\n",
       "        [ 47,  59,  55],\n",
       "        [ 48,  60,  56],\n",
       "        ...,\n",
       "        [ 58,  59,  51],\n",
       "        [ 60,  60,  52],\n",
       "        [ 62,  59,  52]],\n",
       "\n",
       "       [[ 46,  61,  56],\n",
       "        [ 47,  62,  57],\n",
       "        [ 48,  63,  58],\n",
       "        ...,\n",
       "        [ 57,  58,  50],\n",
       "        [ 62,  59,  52],\n",
       "        [ 62,  57,  51]]], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = Image.open(imgs[1])\n",
    "img.show()\n",
    "img = np.array(Image.open(imgs[1]))\n",
    "img "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 773, (512, 773, 3))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h,w, _ = img.shape\n",
    "h, w, img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "261"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim_diff = np.abs(h - w)\n",
    "dim_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(130, 131)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad1, pad2 = dim_diff // 2, dim_diff - dim_diff // 2 # // 2 对半分\n",
    "pad1, pad2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((130, 131), (0, 0), (0, 0))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad = ((pad1, pad2), (0, 0), (0, 0)) if h <= w else ((0, 0), (pad1, pad2), (0, 0))\n",
    "pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "from skimage.transform import resize\n",
    "\n",
    "img_no_padding = Image.fromarray(img.astype('uint8'))\n",
    "# img_no_padding.show() # (512, 773) \n",
    "# Add padding\n",
    "input_img = np.pad(img, pad, 'constant', constant_values=127.5) / 255.\n",
    "img_padding = Image.fromarray(input_img.astype('uint8')).convert('RGB')\n",
    "# img_padding.show() # (773, 773) , 除了255后(归一化),就是一片黑\n",
    "# Resize and normalize\n",
    "print(type(input_img))\n",
    "input_img = resize(input_img, (416, 416, 3), mode='reflect')\n",
    "img_resize = Image.fromarray(input_img.astype('uint8'))\n",
    "# img_resize.show() # (416, 416)\n",
    "print(type(input_img))\n",
    "# input_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 416, 416])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "# Channels-first\n",
    "print(type(input_img))\n",
    "input_img = np.transpose(input_img, (2, 0, 1))\n",
    "# As pytorch tensor\n",
    "input_img = torch.from_numpy(input_img).float()\n",
    "input_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
